{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T07:51:06.386969300Z",
     "start_time": "2024-04-18T07:51:04.906508900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46a516807c173b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T07:51:06.410470100Z",
     "start_time": "2024-04-18T07:51:06.389063200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Suppress DtypeWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53630421909da6db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T07:51:06.429477Z",
     "start_time": "2024-04-18T07:51:06.395579600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Root of project\n",
    "root_dir = os.path.join(\"analysis_data\")\n",
    "os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "# Raw data from api\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Formatted CSV data\n",
    "csv_dir = os.path.join(root_dir, \"csv\")\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "# Data split by location\n",
    "location_dir = os.path.join(root_dir, \"location\")\n",
    "os.makedirs(location_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fa428b6a93ea1b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:03:43.473206600Z",
     "start_time": "2024-04-18T07:51:06.410470100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(start: str, end: str):\n",
    "    data = requests.get(\n",
    "        f\"https://ilm2.site.dustmonitoring.nl/download?from={start}&to={end}&interval=600&align=1&type=csv-semicolon&p=531&p=521&p=542&p=543&p=553&p=544&p=545&p=532&p=533&p=554&p=534&p=535&p=546&p=536&p=556&p=522&p=557&p=547&p=549&p=524&p=537&p=525&p=526&p=539&p=551&p=540&p=558&p=527&p=528&p=529&p=530&p=560&p=561&p=562&p=563&p=564&p=565&p=566&p=567&p=568&p=569&p=570&p=571&p=574&p=575&p=576&p=577&p=578&s=10&s=11&s=128&s=129&s=130&s=145&s=146\"\n",
    "    )\n",
    "    return data.text\n",
    "\n",
    "_date = date(2020, 11, 1)\n",
    "\n",
    "while True:\n",
    "    start_date = _date\n",
    "    end_date = _date + relativedelta(months=2)\n",
    "    data = get_data(start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    file_path = os.path.join(data_dir, f\"data_{start_date.strftime('%Y-%m-%d')}.csv\")\n",
    "\n",
    "    with open(file_path, \"+w\") as file:\n",
    "        file.write(data)\n",
    "\n",
    "    _date = end_date\n",
    "    if _date > date(2024, 3, 1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a90206e45f939dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:03:57.723623400Z",
     "start_time": "2024-04-18T08:03:43.478357900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in os.listdir(data_dir):\n",
    "\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "    df = pd.read_csv(file_path, index_col=False, sep=\";\")\n",
    "\n",
    "    # Get the values of the first 2 rows\n",
    "    header_string = df.iloc[:2].values\n",
    "    row_1 = [row.split(\".\")[0] for row in df.columns.tolist()]\n",
    "    row_2 = header_string[0]\n",
    "\n",
    "    # Merge these into the new column names\n",
    "    new_columns = []\n",
    "    for row1, row2 in zip(row_1, row_2):\n",
    "        row1 = row1.replace(\"Unnamed: \", \"\")\n",
    "        new_columns.append(f\"{row1}-{row2}\")\n",
    "    # Remove the used rows\n",
    "    df = df.iloc[2:]\n",
    "    # Set new column names\n",
    "    df.columns = new_columns\n",
    "    \n",
    "    csv_file_path = os.path.join(csv_dir, file)\n",
    "    # Convert all columns to string\n",
    "    df = df.astype(str)\n",
    "    # Replace all commas with dots\n",
    "    df = df.replace(\",\", \".\", regex=True)\n",
    "\n",
    "    df.to_csv(csv_file_path, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c15764efb671e3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:04:04.178620200Z",
     "start_time": "2024-04-18T08:03:57.725701800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185121, 287)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all monthly datasets\n",
    "dfs = []\n",
    "for file in os.listdir(csv_dir):\n",
    "    csv_file_path = os.path.join(csv_dir, file)\n",
    "    df = pd.read_csv(csv_file_path, index_col=False)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Join datasets togather into one\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "406a1275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time should be unique! Found 2900 duplicates\n"
     ]
    }
   ],
   "source": [
    "if not df[\"0-Tijd\"].is_unique:\n",
    "    print(f\"Time should be unique! Found {df['0-Tijd'].duplicated().sum()} duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79e30d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm10 = (\n",
    "    df\n",
    "    .assign(**{\"0-Tijd\": pd.to_datetime(df[\"0-Tijd\"])})\n",
    "    .set_index(\"0-Tijd\")\n",
    "    .loc[:, lambda x: x.columns.str.contains(\"PM10\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2c70e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing fraction of I02-PM10: 2.04%\n",
      "Missing fraction of I09-PM10: 2.08%\n",
      "Missing fraction of I11-PM10: 2.22%\n",
      "Missing fraction of I12-PM10: 3.38%\n",
      "Missing fraction of I24-PM10: 0.59%\n",
      "Missing fraction of I25-PM10: 3.67%\n",
      "Missing fraction of I29-PM10: 1.88%\n",
      "Missing fraction of I32-PM10: 0.46%\n",
      "Missing fraction of I36-PM10: 3.98%\n",
      "Missing fraction of I37-PM10: 0.12%\n",
      "Missing fraction of I39-PM10: 7.96%\n",
      "Missing fraction of I40-PM10: 3.98%\n",
      "Missing fraction of I04-PM10: 4.42%\n",
      "Missing fraction of I07-PM10: 0.62%\n",
      "Missing fraction of I08-PM10: 31.59%\n",
      "Missing fraction of I14-PM10: 1.63%\n",
      "Missing fraction of I17-PM10: 6.93%\n",
      "Missing fraction of I19-PM10: 0.41%\n",
      "Missing fraction of I22-PM10: 10.95%\n",
      "Missing fraction of I23-PM10: 1.41%\n",
      "Missing fraction of I28-PM10: 0.19%\n",
      "Missing fraction of I30-PM10: 1.34%\n",
      "Missing fraction of I03-PM10: 0.05%\n",
      "Missing fraction of I05-PM10: 5.15%\n",
      "Missing fraction of I10-PM10: 16.18%\n",
      "Missing fraction of I16-PM10: 2.33%\n",
      "Missing fraction of I33-PM10: 0.14%\n",
      "Missing fraction of I41-PM10: 3.15%\n",
      "Missing fraction of I43-PM10: 0.10%\n",
      "Missing fraction of I13-PM10: 0.36%\n",
      "Missing fraction of I18-PM10: 0.83%\n",
      "Missing fraction of I42-PM10: 0.09%\n",
      "Missing fraction of I44-PM10: 0.09%\n",
      "Missing fraction of I45-PM10: 0.38%\n",
      "Missing fraction of I48-PM10: 7.77%\n",
      "Missing fraction of I49-PM10: 0.06%\n",
      "Missing fraction of I51-PM10: 0.08%\n",
      "Missing fraction of I52-PM10: 4.28%\n",
      "Missing fraction of I46-PM10: 9.76%\n",
      "Missing fraction of I47-PM10: 0.15%\n",
      "Missing fraction of I56-PM10: 0.10%\n",
      "Missing fraction of I58-PM10: 3.67%\n",
      "Missing fraction of I55-PM10: 0.57%\n",
      "Missing fraction of I50-PM10: 1.13%\n",
      "Missing fraction of I01-PM10: 0.05%\n",
      "Missing fraction of I06-PM10: 21.09%\n",
      "Missing fraction of I59-PM10: 0.00%\n"
     ]
    }
   ],
   "source": [
    "for column in pm10.columns:\n",
    "    print(f\"Missing fraction of {column}: {pm10[column].dropna().resample(\"1h\").mean().isna().mean():.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
